---
layout: post
title: "Lesson 03: Cleaning & Subsetting Time Series Data - NoData Values & Subset by Date in R"
date: 2015-10-22
authors: [Megan A. Jones, Marisa Guarinello, Courtney Soderberg]
contributors: [Leah A. Wasser]
dateCreated: 2015-10-22
lastModified: `r format(Sys.time(), "%Y-%m-%d")`
tags: [spatio-temporal, time-series, phenology]
mainTag: time-series
packagesLibraries: [lubridate, ggplot2]
category: 
description: "This tutorial explores how to deal with NoData values encountered
in a time series dataset - in R. It also covers how to subset large data files 
by date and export the results to a csv (text format) file."
code1: TS03-Subset-Data-and-No-Data-Values-In-R.R
image:
  feature: NEONCarpentryHeader_2.png
  credit: A collaboration between the National Ecological Observatory Network (NEON) and Data Carpentry
  creditlink: http://www.neoninc.org
permalink: /R/Subset-Data-and-No-Data-Values
comments: false
---

{% include _toc.html %}

##About
This tutorial explores how to deal with NoData values encountered
in a time series dataset - in R. It also covers how to subset large data files 
by date and export the results to a csv (text format) file.

**R Skill Level:** Intermediate - you've got the basics of `R` down and 
understand the general structure of tabular data.

<div id="objectives" markdown="1">

### Goals / Objectives
After completing this activity, you will:

 * Be able to subset data by date. 
 * Know how to search for NA or missing data values. 
 * Understand different possibilities on how to deal with missing data. 

**To complete this lesson:** you will need the most current version of R, and 
preferably RStudio, loaded on your computer.

####R Libraries to Install

* **lubridate:** `install.packages("lubridate")`
* **ggplot2:** `install.packages("ggplot2")`

<a href="http://neondataskills.org/R/Packages-In-R/" target="_blank">
More on Packages in R - Adapted from Software Carpentry.</a>

####Data to Download

<a href="https://ndownloader.figshare.com/files/3579861" class="btn btn-success">
Download Atmospheric Teaching Data Subset</a>

The data used in this lesson were collected at Harvard Forest which is
a National Ecological Observatory Network <a href="http://www.neoninc.org/science-design/field-sites/harvard-forest" target="_blank"> field site</a>. These data are proxy data for what will be 
available for 30 years on the [NEON data portal](http://data.neoninc.org/ "NEON data")
for both Harvard Forest and other field sites located across the United States.


**Set Working Directory:** This lessons assumes that you have set your working 
directory to the location of the downloaded and unzipped data subset. [An overview
of setting the working directory in `R` can be found here.]({{site.baseurl}}/R/Set-Working-Directory "R Working Directory Lesson") 
lesson prior to beginning this lesson.

**Challenge Code:** NEON Data lesson often contain challenges that reinforce 
learned skills. If available, the code for challenge solutions is found in a 
downloadable `R` script available on the footer of each lesson page.

###Additional Resources

</div>

#Cleaning Time Series Data 
No dataset is perfect. It is common to encounter, large files containing more
data than we need for our analysis. It is also common to encounter `noData` values
that we need to account for when analyzing our data. 

In this tutorial, we'll learn about ways to both manage `noData` values and also 
subset and export a portion of an R object as a new `.CSV` file. 

In this lesson, we will work with atmospheric data, containing air temperature, 
precipitation, and photosynthetically active radiation (PAR) data  - metrics that 
are key drivers of phenology. Our study area is the NEON Harvard Forest Field Site.

We will use the `lubridate` and `ggplot2` packages. Let's load those first.

If you have not already done so, import the `hf001-10-15min-m.csv` file, which contains
our atmospheric data for Harvard Forest. Convert the `datetime` column to a `POSIXct` 
class: [As covered in Time Series Lesson 02]({{ site.baseurl }}/R/Time-Series-Metadata/). 

```{r load-libraries}
# Load packages required for entire script
library(lubridate)  #work with dates
library(ggplot2)  # plotting

#set working directory to ensure R can find the file we wish to import
#setwd("working-dir-path-here")

#Load csv file containing 15 minute averaged atmospheric data 
# for the NEON Harvard Forest Field Site

#Factors=FALSE so data are imported as numbers and characters 
harMet_15Min <- read.csv(file="NEON-DS-Met-Time-Series/HARV/FisherTower-Met/hf001-10-15min-m.csv",
                     stringsAsFactors = FALSE)

#convert to POSIX date time class - US Eastern Time Zone
harMet_15Min$datetime <- as.POSIXct(harMet_15Min$datetime,
                                format = "%Y-%m-%dT%H:%M",
                                tz = "America/New_York")

```

##Subset by Date
Our `.csv` file contains nearly a decade's worth of data which makes for a large
file. The time period we are interested in for our study is:

* Start Time: 1 January 2009
* End Time: 31 Dec 2011

Let's subset the data to only contain these three years. We can use the 
`subset()` function, with the syntax:
`NewObject <- subset ( ObjectToBeSubset, CriteriaForSubsetting ) `.  

We will set our criteria to be "any `datetime` that:

1. Is greater than or equal to 1 Jan 2009 at 0:00 
**AND** 
2. Is less than or equal to 31 Dec 2011 at 23:59".

We also need to specify the `timezone` so `R` can handle daylight savings and leap
year.

``` {r subset-by-time }
#subset data - 2009-2011
harMet15.09.11 <- subset(harMet_15Min, datetime >= as.POSIXct('2009-01-01 00:00',
        tz = "America/New_York") & datetime <=
        as.POSIXct('2011-12-31 23:59', tz = "America/New_York"))

# View first and last records in the object 
head(harMet15.09.11[1])
tail(harMet15.09.11[1])

```

It worked! The first entry is 1 January 2009 at 00:00 and the last entry is 31
December 2011 at 23:45.

##Export data.frame to .CSV

We can export this subset in `.csv` format to use in other analyses or to 
share with colleagues using `write.csv`. 

<i class="fa fa-star"></i> **Data Tip:** Remember, to give your output files
concise, yet descriptive names so you can identify what it contains in the future. 
By default, the `.csv` file will be written to your working directory. 
{: .notice}


``` {r write-csv}
#writing the subset of harMet15 data to .csv
write.csv(harMet15.09.11, file="Met_HARV_15min_2009_2011.csv")

```

<div id="challenge" markdown="1">
#Challenge: Subsetting & Plotting

Plot precipitation data for the month of July 2010 in Harvard Forest.

</div>

``` {r challenge-code-subsetting, include=TRUE, results="hide", echo=FALSE}

#subset out data points from July 2010
harMet15_July2010 <- subset(harMet15.09.11, datetime >= as.POSIXct('2010-07-01 00:00',
        tz = "America/New_York") & datetime <=
        as.POSIXct('2010-07-31 23:59', tz = "America/New_York"))

#view first and last rows of data.frame to ensure subset worked
head(harMet15_July2010$datetime)
tail(harMet15_July2010$datetime)

#plot precip data for July 2010
qplot (datetime, prec,
       data= harMet15_July2010,
       main= "Precipitation: July 2010\nNEON Harvard Forest Field Site",
       xlab= "Date", ylab= "Precipitation (mm)")
```


## Managing Missing Data: NoData values

###Checking for NoData Values
In the [Time Series Metadata Lesson ]({{site.baseurl}}/R/Time-Series-Metadata/ "Time Series Metadata")
we viewed the metadata for these data and discovered that missing values are designated
using `NA` - a common NoData value placeholder. 

**Excerpt from the metadata:** `airt: average air temperature. Average of daily 
averages. (unit: celsius / missing value: NA)`

If we are lucky when working with external data, the `NoData` value is clearly specified
in the metadata. Sometimes this value is `NA` or `nan` (not a number). However, 
`NA` isn't always used. Text values can make data storage difficult for some 
programs and thus, sometimes you'll encounter a large negative value such as `-9999`
used as the `noData` value. Othertimes, we might see blank values in a data file
which designate `noData`. Blanks are particularly problematic because we can't be 
certain if a data value is purposefully missing (not measured that day or a bad
measurement) OR if someone unintentionally deleted it.

Because the actual value used to designate missing data can vary depending upon 
what data we are working with, it is important to always check the metadata for
the files associated `noData` value. If the value is `NA`, we are in luck, `R` will
recognize and flag this value as `noData`. If the value is numeric (e.g. `-9999`),
then we might need to assign this value to `NA`.

<i class="fa fa-star"></i> **Data Tip:** `NA` values will be ignored when
performing calculations in R. However a `noData` value of `-9999` will be recognized
as an integer and processed accordingly. If you encounter a numeric `noData` value
be sure to assign it to `NA` in R as follows: `objectName[objectName==-9999] <- NA`
{: .notice}

###Check For noData Values 

We can quickly check for `noData` values in our data using the`is.na()` function. 
By asking for the `sum()` of `is.na()` we can see how many NA/missing values we have. 

```{r missing values}

#Check for NA values
sum(is.na(harMet15.09.11$datetime))
sum(is.na(harMet15.09.11$airt))


#view rows where the air temperature is NA 
harMet15.09.11[is.na(harMet15.09.11$airt),]
```

The results above tell us there are `noData` values in the `datetime` column.
However, there are `noData` values in other variables.  

<div id="challenge" markdown="1">
#Challenge: NoData Values

* How many `noData` values are in the prec and parr columns of our data?

</div>

```{r no-data-value-challenge, echo=FALSE, results="hide"}
#check for no data values
sum(is.na(harMet15.09.11$prec))
sum(is.na(harMet15.09.11$parr))

```


###Deal with noData Values
When we encounter `noData` values (blank, NaN, -9999, etc.) in our data we
need to decide how to deal with them. By default `R` treats `noData` values designated
with a `NA` as a missing value rather than a zero. This is good, as a value of 
zero (no rain today) is not the same as missing data (e.g. we didn't measure the 
amount of rainfall today). 

How we deal with `noData` values will depend on:

* the data type we are working with
* the analysis we are conducting 
* the significance of the gap or missing value

Sometimes we might need to "gap fill" our data. This means we will interpolate 
or estimate missing values often using statistical methods. Gap filling can be 
complex and is beyond the scope of this lesson. The take away from this lessons is
simply that it is important to acknowledge missing values in your data and to 
carefully consider how you wish to account for them during analysis. 

Other resources:

1. <a href="http://www.statmethods.net/input/missingdata.html" target="_blank"> Quick-R: Missing  Data</a> 
 -- R code for dealing with missing data 
2. The Institute for Digital Research and Education has an <a href="http://www.ats.ucla.edu/stat/r/faq/missing.htm" target="_blank"> R FAQ on Missing Values</a>.

### Managing noData Values in Our Data

For this lesson, we are exploring the patterns of precipitation,
and termperature as they related to green-up and brown-down of vegetation at 
Harvard Forest. To view overall trends during these early exploration stages, it 
is ok for us to leave out the `noData` values in our plots. 


<i class="fa fa-star"></i> **Data Tip:** If we wanted to perform more advanced 
statistical analysis, we might consider gap-filling as our next step. Many data 
products, from towers such as FluxNet include a higher level, already gap-filled
product that we can download! <a href="http://www.archive.arm.gov/Carbon/gapfilling/gapfilling.html"
target="_blank">More on Gap Filling</a>
{: .notice}


### noData Values Can Impact Calculations

It is important to consider `noData` values when performing calculations on our
data. For example, `R` will not properly calculate certain functions if there are 
`NA` values in the data, unless we explicetly tell it to ignore them. 

``` {r na-in-calculations}

#calculate mean of air temperature
mean(harMet15.09.11$airt)

```

`R` will not return a value for the mean as there `NA` values in the air 
temperature column. Because there are only 2 missing values (out of 105,108) for 
air temperature, we aren't that worried about a skewed 3 year mean. We can tell 
`R` to ignore missing values in the mean calculations using `na.rm=` (NA.remove).

``` {r na-rm}
#calculate mean of air temperature, ignore NA values
mean(harMet15.09.11$airt, 
     na.rm=TRUE)

```

We now see that the 3-year average air temperature is 8.5°C.  

<div id="challenge" markdown="1">

## Challenge: Import, Understand Metadata, and Clean a Data Set
We have been using the 15-minute data from the Harvard Forest. However, overall
we are interested in larger scale patterns of greening-up and browning-down.  
Thus a daily summary is sufficient for us to see overall trends.

1. Import the Daily Meteorological data from the Harvard Forest (if you haven't already done so in the [Brief Tabular Time Series lesson ]({{site.baseurl}}/R/Brief-Tabular-Time-Series-qplot/ "for HarMet_Daily"). )
2. Check the metadata to see what the column names are for the variable of
interest (precipitation, air temperature, PAR, day and time ).
3. If needed, convert the data class of different columns.
4. Check for missing data and decide what to do with any that exist.
5. Subset out the data for the duration of our study: 2009-2011. Name the object 
"harMetDaily.09.11".
6. Export the subset to a `.csv` file. 
7. Create a plot of Daily Air Temperature for 2009-2011. Be sure to label, x and y
axes. Also give the plot a title! 

</div>

``` {r Challenge-code-harMet.daily, include=TRUE, results="hide", echo=FALSE}

#1. import daily file
harMet.daily <- read.csv("NEON-DS-Met-Time-Series/HARV/FisherTower-Met/hf001-06-daily-m.csv", 
      stringsAsFactors = FALSE)
#view file structure
str(harMet.daily)

#2. Metadata
#Differences in 2 variable names PAR=part, DateTime=date

#3. convert date 
harMet.daily$date <- as.Date(harMet.daily$date,format = "%Y-%m-%d")
#view structure
str(harMet.daily [1])


#4. Check for noData values
sum(is.na(harMet.daily$date))
sum(is.na(harMet.daily$airt))
sum(is.na(harMet.daily$prec))
sum(is.na(harMet.daily$part))
#OuputNote: PART is missing 1032 values

#5. subset out some of the data - 2009-2011
harMetDaily.09.11 <- subset(harMet.daily, date >= as.Date('2009-01-01')
                                        & date <= as.Date('2011-12-31'))

#view first and last rows of the data
head(harMetDaily.09.11$date)
tail(harMetDaily.09.11$date)

#do we still have the NA in part?
sum(is.na(harMetDaily.09.11$part))
#Output note: now only 1 NA!

#6. Write .csv
write.csv(harMetDaily.09.11, file="Met_HARV_Daily_2009_2011.csv")


#7.  Plotting air temp 2009-2011
qplot (x=date, y=airt,
       data=harMetDaily.09.11,
       main= "Average Air Temperature \n Harvard Forest",
       xlab="Date", ylab="Temperature (°C)")
```

